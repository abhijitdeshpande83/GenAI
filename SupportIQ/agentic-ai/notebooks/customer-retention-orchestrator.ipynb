{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6d275839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "from typing import Annotated, TypedDict, List, Sequence\n",
    "from langchain_groq import ChatGroq \n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import BaseMessage,HumanMessage,SystemMessage,AIMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.prebuilt import InjectedState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0357fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b887cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1cbc24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisorState(MessagesState):\n",
    "    \"\"\"\n",
    "        State for multi-agent system\n",
    "    \"\"\"   \n",
    "    next_agent: str\n",
    "    user_input: str\n",
    "    user_intent: str\n",
    "    complaint: List[dict]\n",
    "    question:  List[dict]\n",
    "\n",
    "# Supervisor Node\n",
    "\n",
    "def supervisor_node(state:SupervisorState)->SupervisorState:\n",
    "    system_prompt = \"\"\"\n",
    "        You are a supervisor. Based on user query decide the intent.\n",
    "        Options: inquiry, complaint, retention. Just return the intent.\n",
    "\n",
    "        - \"My laptop stopped working\" -> complaint\n",
    "        - \"Show me more info on my TCL TV\" -> inquiry\n",
    "        - \"I want to cancel my Netflix subscription\" -> retention\n",
    "        - \"My smartphone battery is not charging\" -> complaint\n",
    "        - \"I want to know the specs of my AirPods\" -> inquiry\n",
    "        - \"I want to cancel my gym membership\" -> retention\n",
    "        \"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        {\"role\":\"system\", \"content\":system_prompt},\n",
    "        {\"role\":\"user\", \"content\":state[\"user_input\"]}\n",
    "        ])\n",
    "    \n",
    "    intent=response.content.strip().lower()\n",
    "    print(\"Intent is:\",intent)\n",
    "    if intent==\"inquiry\":\n",
    "        return Command(goto=\"Inquiry Agent\")\n",
    "    elif intent==\"complaint\":\n",
    "        return Command(goto=\"Complaint Agent\")\n",
    "    elif intent==\"retention\":\n",
    "        return Command(goto=\"Retention Agent\")\n",
    "    else:\n",
    "        return Command(goto=\"Fallback\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7c2eb31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worker nodes\n",
    "\n",
    "def inquiry_node(state:SupervisorState)->SupervisorState:\n",
    "    return {'messages':[f\"Inquiry Handled: {state['user_input']}\"]}\n",
    "\n",
    "def retention_node(state:SupervisorState)->SupervisorState:\n",
    "    return {'messages':[f\"Retention Handled: {state['user_input']}\"]}\n",
    "\n",
    "def fallback(state:SupervisorState)->SupervisorState:\n",
    "    return {'messages':[f\"Sorry, I couldn't understand your message\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f8413a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def nlu(user_input:str)->dict:\n",
    "    \"\"\"It extracts the entities from the user input\"\"\"\n",
    "\n",
    "    system_prompt=\"\"\"\n",
    "    Extract the following from the customer message:\n",
    "    - product\n",
    "    - issue_type\n",
    "    - purchase_date\n",
    "\n",
    "    Respond ONLY with a valid JSON object in this exact format:\n",
    "    {\n",
    "        \"product\": string or null,\n",
    "        \"issue_type\": string or null,\n",
    "        \"purchase_date\": string or null\n",
    "    }\"\"\"\n",
    "    response = llm.invoke([\n",
    "        {'role':'system','content':system_prompt},\n",
    "        {'role':'user','content':user_input}\n",
    "    ])\n",
    "    complaint = json.loads(response.content) \n",
    "    return {'complaint':complaint}\n",
    "\n",
    "@tool\n",
    "def ask_missing_info(missing_values:List[str])->dict:\n",
    "    \"\"\"\n",
    "    It will ask the missing information to user to get the \n",
    "    remaining details missing from the user input\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt=f\"\"\"You are a helpful assistant.\n",
    "        Ask the user for the missing information in a clear and concise way, \n",
    "        one piece at a time, so we can complete the complaint record.\n",
    "        Missing values are: {missing_values}\n",
    "        \"\"\"\n",
    "    response = llm.invoke([{'role':'system','content':system_prompt}])\n",
    "    return {'question':response.content}\n",
    "\n",
    "@tool\n",
    "def create_ticket(complaint: dict)->dict:\n",
    "    \"\"\"\n",
    "    Tool to create a complaint ticket.\n",
    "    Generates a ticket ID like IG408C90.\n",
    "    \"\"\"\n",
    "    prefix = ''.join(random.choices(string.ascii_uppercase,k=2))\n",
    "    number1 = random.randint(100,1000)\n",
    "    mid = ''.join(random.choices(string.ascii_uppercase))\n",
    "    number2 = random.randint(10,100)\n",
    "    ticket_id = f\"{prefix}{number1}{mid}{number2}\"\n",
    "\n",
    "    ticket={\n",
    "        \"ticket_id\":ticket_id,\n",
    "        \"status\":\"created\",\n",
    "        \"details\":complaint\n",
    "    }\n",
    "    \n",
    "    return ticket\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fc104327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complaint_node(state:SupervisorState)->SupervisorState:\n",
    "   \"\"\"\n",
    "      This node handles complaint and helps to resolve complaint.  \n",
    "   \"\"\"\n",
    "   # system_prompt = \"\"\"\n",
    "   # You are an assistant. Use nlu tool to extract product, issue_type, purchase_date\n",
    "   # from customer messages whenever needed.\n",
    "   # \"\"\" \n",
    "   # llm_tool = llm.bind_tools([nlu])\n",
    "   # response = llm_tool.invoke([{'role':'system','content':system_prompt},\n",
    "   #                            {'role':'user','content':state['user_input']}])\n",
    "\n",
    "   \n",
    "   extracted=nlu(state['user_input'])\n",
    "   print(extracted)\n",
    "   missing_values=[k for k,v in extracted['complaint'].items() if v is None]\n",
    "   print(\"Missing Values\", missing_values)\n",
    "\n",
    "   question=ask_missing_info({'missing_values':missing_values})\n",
    "   print(question)\n",
    "   state['question']=question\n",
    "\n",
    "   print(\"creating ticket\")\n",
    "   ticket=create_ticket(extracted)\n",
    "   print(ticket)\n",
    "\n",
    "   return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1ca3c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(SupervisorState)\n",
    "graph.add_node(\"Supervisor\",supervisor_node)\n",
    "graph.add_node(\"Inquiry Agent\",inquiry_node)\n",
    "graph.add_node(\"Complaint Agent\",complaint_node)\n",
    "graph.add_node(\"Retention Agent\",retention_node)\n",
    "graph.add_node(\"Fallback\", fallback)\n",
    "\n",
    "graph.add_edge(START, \"Supervisor\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "20918bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 23:32:54,389 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent is: inquiry\n"
     ]
    }
   ],
   "source": [
    "response = app.invoke({\"user_input\":\"I want to know about iphone17pro\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76adc2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097527a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590802d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7034adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f808c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e54004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688dcb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe763e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
